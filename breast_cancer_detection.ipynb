{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breast cancer detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG3RPoSX_N4j"
      },
      "source": [
        "import pandas as pd # for data manupulation or analysis\n",
        "import numpy as np # for numeric calculation\n",
        "import matplotlib.pyplot as plt # for data visualization\n",
        "import seaborn as sns # for data visualization"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isqLeiGx_XGF",
        "outputId": "4dc04a8a-b9de-4b01-dd16-b94c3deca644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer_dataset = load_breast_cancer()\n",
        "print(\"type of data : \",type(cancer_dataset))\n",
        "print(\"keys for data set :  \",cancer_dataset.keys())\n",
        "print(\"name of the features : \",cancer_dataset['feature_names'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type of data :  <class 'sklearn.utils.Bunch'>\n",
            "keys for data set :   dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
            "name of the features :  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKmdoFmz_3r8",
        "outputId": "9148bbba-fe8e-4409-e019-33bbbee2d107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(cancer_dataset['filename'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/breast_cancer.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpwXpKcLBxUJ"
      },
      "source": [
        "# create datafrmae\n",
        "cancer_df = pd.DataFrame(np.c_[cancer_dataset['data'],cancer_dataset['target']],columns = np.append(cancer_dataset['feature_names'], ['target']))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHdQkSXaB_ya",
        "outputId": "b5877790-d422-4485-b5a3-3cdf7668ac53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "cancer_df.tail(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>11.51</td>\n",
              "      <td>23.93</td>\n",
              "      <td>74.52</td>\n",
              "      <td>403.5</td>\n",
              "      <td>0.09261</td>\n",
              "      <td>0.10210</td>\n",
              "      <td>0.11120</td>\n",
              "      <td>0.04105</td>\n",
              "      <td>0.1388</td>\n",
              "      <td>0.06570</td>\n",
              "      <td>0.2388</td>\n",
              "      <td>2.904</td>\n",
              "      <td>1.936</td>\n",
              "      <td>16.97</td>\n",
              "      <td>0.008200</td>\n",
              "      <td>0.029820</td>\n",
              "      <td>0.05738</td>\n",
              "      <td>0.01267</td>\n",
              "      <td>0.01488</td>\n",
              "      <td>0.004738</td>\n",
              "      <td>12.480</td>\n",
              "      <td>37.16</td>\n",
              "      <td>82.28</td>\n",
              "      <td>474.2</td>\n",
              "      <td>0.12980</td>\n",
              "      <td>0.25170</td>\n",
              "      <td>0.3630</td>\n",
              "      <td>0.09653</td>\n",
              "      <td>0.2112</td>\n",
              "      <td>0.08732</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>14.05</td>\n",
              "      <td>27.15</td>\n",
              "      <td>91.38</td>\n",
              "      <td>600.4</td>\n",
              "      <td>0.09929</td>\n",
              "      <td>0.11260</td>\n",
              "      <td>0.04462</td>\n",
              "      <td>0.04304</td>\n",
              "      <td>0.1537</td>\n",
              "      <td>0.06171</td>\n",
              "      <td>0.3645</td>\n",
              "      <td>1.492</td>\n",
              "      <td>2.888</td>\n",
              "      <td>29.84</td>\n",
              "      <td>0.007256</td>\n",
              "      <td>0.026780</td>\n",
              "      <td>0.02071</td>\n",
              "      <td>0.01626</td>\n",
              "      <td>0.02080</td>\n",
              "      <td>0.005304</td>\n",
              "      <td>15.300</td>\n",
              "      <td>33.17</td>\n",
              "      <td>100.20</td>\n",
              "      <td>706.7</td>\n",
              "      <td>0.12410</td>\n",
              "      <td>0.22640</td>\n",
              "      <td>0.1326</td>\n",
              "      <td>0.10480</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.08321</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>11.20</td>\n",
              "      <td>29.37</td>\n",
              "      <td>70.67</td>\n",
              "      <td>386.0</td>\n",
              "      <td>0.07449</td>\n",
              "      <td>0.03558</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1060</td>\n",
              "      <td>0.05502</td>\n",
              "      <td>0.3141</td>\n",
              "      <td>3.896</td>\n",
              "      <td>2.041</td>\n",
              "      <td>22.81</td>\n",
              "      <td>0.007594</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.01989</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>11.920</td>\n",
              "      <td>38.30</td>\n",
              "      <td>75.19</td>\n",
              "      <td>439.6</td>\n",
              "      <td>0.09267</td>\n",
              "      <td>0.05494</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>0.05905</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>15.22</td>\n",
              "      <td>30.62</td>\n",
              "      <td>103.40</td>\n",
              "      <td>716.9</td>\n",
              "      <td>0.10480</td>\n",
              "      <td>0.20870</td>\n",
              "      <td>0.25500</td>\n",
              "      <td>0.09429</td>\n",
              "      <td>0.2128</td>\n",
              "      <td>0.07152</td>\n",
              "      <td>0.2602</td>\n",
              "      <td>1.205</td>\n",
              "      <td>2.362</td>\n",
              "      <td>22.65</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.048440</td>\n",
              "      <td>0.07359</td>\n",
              "      <td>0.01608</td>\n",
              "      <td>0.02137</td>\n",
              "      <td>0.006142</td>\n",
              "      <td>17.520</td>\n",
              "      <td>42.79</td>\n",
              "      <td>128.70</td>\n",
              "      <td>915.0</td>\n",
              "      <td>0.14170</td>\n",
              "      <td>0.79170</td>\n",
              "      <td>1.1700</td>\n",
              "      <td>0.23560</td>\n",
              "      <td>0.4089</td>\n",
              "      <td>0.14090</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>20.92</td>\n",
              "      <td>25.09</td>\n",
              "      <td>143.00</td>\n",
              "      <td>1347.0</td>\n",
              "      <td>0.10990</td>\n",
              "      <td>0.22360</td>\n",
              "      <td>0.31740</td>\n",
              "      <td>0.14740</td>\n",
              "      <td>0.2149</td>\n",
              "      <td>0.06879</td>\n",
              "      <td>0.9622</td>\n",
              "      <td>1.026</td>\n",
              "      <td>8.758</td>\n",
              "      <td>118.80</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.043100</td>\n",
              "      <td>0.07845</td>\n",
              "      <td>0.02624</td>\n",
              "      <td>0.02057</td>\n",
              "      <td>0.006213</td>\n",
              "      <td>24.290</td>\n",
              "      <td>29.41</td>\n",
              "      <td>179.10</td>\n",
              "      <td>1819.0</td>\n",
              "      <td>0.14070</td>\n",
              "      <td>0.41860</td>\n",
              "      <td>0.6599</td>\n",
              "      <td>0.25420</td>\n",
              "      <td>0.2929</td>\n",
              "      <td>0.09873</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.256</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.028910</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.22160</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.463</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.024230</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.16280</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.075</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.037310</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.14180</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.595</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.061580</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.26500</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.428</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.004660</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "559        11.51         23.93  ...                  0.08732     1.0\n",
              "560        14.05         27.15  ...                  0.08321     1.0\n",
              "561        11.20         29.37  ...                  0.05905     1.0\n",
              "562        15.22         30.62  ...                  0.14090     0.0\n",
              "563        20.92         25.09  ...                  0.09873     0.0\n",
              "564        21.56         22.39  ...                  0.07115     0.0\n",
              "565        20.13         28.25  ...                  0.06637     0.0\n",
              "566        16.60         28.08  ...                  0.07820     0.0\n",
              "567        20.60         29.33  ...                  0.12400     0.0\n",
              "568         7.76         24.54  ...                  0.07039     1.0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt6WhbDoCF35",
        "outputId": "82011e93-b02e-47db-8480-5726043e0784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cancer_df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  target                   569 non-null    float64\n",
            "dtypes: float64(31)\n",
            "memory usage: 137.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcJm5Y4nCpSU",
        "outputId": "e73340eb-9893-415f-c3d9-5eeb641bf732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# input variable\n",
        "X = cancer_df.drop(['target'], axis = 1)\n",
        "print(X.tail(6))\n",
        "\n",
        "# output variable\n",
        "y = cancer_df['target']\n",
        "print(y.tail(5))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
            "563        20.92         25.09  ...          0.2929                  0.09873\n",
            "564        21.56         22.39  ...          0.2060                  0.07115\n",
            "565        20.13         28.25  ...          0.2572                  0.06637\n",
            "566        16.60         28.08  ...          0.2218                  0.07820\n",
            "567        20.60         29.33  ...          0.4087                  0.12400\n",
            "568         7.76         24.54  ...          0.2871                  0.07039\n",
            "\n",
            "[6 rows x 30 columns]\n",
            "564    0.0\n",
            "565    0.0\n",
            "566    0.0\n",
            "567    0.0\n",
            "568    1.0\n",
            "Name: target, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkdQMYWVEz1Z"
      },
      "source": [
        "# split dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 5)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lpyu7SrIG74"
      },
      "source": [
        "# Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train_sc = sc.fit_transform(X_train)\n",
        "X_test_sc = sc.transform(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aczl3moILUm"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9QVj3GbIPfe",
        "outputId": "03cd9ae6-aac2-4a0c-fa18-59aebe33ba92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# XGBoost Classifier\n",
        "# from xgboost import XGBClassifier\n",
        "# xgb_classifier2 = XGBClassifier()\n",
        "# xgb_classifier2.fit(X_train_sc, y_train)\n",
        "# y_pred_xgb_sc = xgb_classifier2.predict(X_test_sc)\n",
        "# accuracy_score(y_test, y_pred_xgb_sc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9824561403508771"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n84O65ZAJgWH",
        "outputId": "19cd19bd-b05b-4eb3-ed33-da01a3f92f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_classifier = LogisticRegression(random_state = 51, penalty = 'none',max_iter=100)\n",
        "lr_classifier.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='none',\n",
              "                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s45gUM84RLRy",
        "outputId": "35099a8b-fba7-4847-cdee-ab501320a5f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_lr = lr_classifier.predict(X_test)\n",
        "print(\"Accuracy by logistic regression for all 30 parameters : \",accuracy_score(y_test, y_pred_lr))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy by logistic regression for all 30 parameters :  0.9736842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcAJcyF_MLJd"
      },
      "source": [
        "# Confusion matrix\n",
        "\n",
        "# cm = confusion_matrix(y_test, y_pred_lr)\n",
        "# plt.title('Heatmap of Confusion Matrix', fontsize = 15)\n",
        "# sns.heatmap(cm, annot = True)\n",
        "# plt.show()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKKNFZBpO2xB",
        "outputId": "0c3ec47e-b170-4a31-fe53-ccc7e9e4cd9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.96      0.97        48\n",
            "         1.0       0.97      0.98      0.98        66\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAY1_-OSO_--",
        "outputId": "39ff6d93-7f54-4a85-99d6-390f090534bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cancer_df_meanone=cancer_df[[\"mean radius\",\"mean texture\",\"mean perimeter\",\"mean area\",\"mean smoothness\", \"mean compactness\",\"mean concavity\",\"mean concave points\",\"mean symmetry\",\"mean fractal dimension\", \"target\"]]\n",
        "print(cancer_df_meanone.head(5))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   mean radius  mean texture  ...  mean fractal dimension  target\n",
            "0        17.99         10.38  ...                 0.07871     0.0\n",
            "1        20.57         17.77  ...                 0.05667     0.0\n",
            "2        19.69         21.25  ...                 0.05999     0.0\n",
            "3        11.42         20.38  ...                 0.09744     0.0\n",
            "4        20.29         14.34  ...                 0.05883     0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5ycOnF6jHeP",
        "outputId": "28ff0370-aa23-41bb-bebf-642d7a1a3b41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# input variable\n",
        "X_mean = cancer_df_meanone.drop(['target'], axis = 1)\n",
        "print(X.tail(6))\n",
        "\n",
        "# output variable\n",
        "y_mean = cancer_df_meanone['target']\n",
        "print(y.tail(5))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_mean, X_test_mean, y_train_mean, y_test_mean = train_test_split(X_mean, y_mean, test_size = 0.2, random_state= 5)\n",
        "\n",
        "# Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train_mean_sc = sc.fit_transform(X_train_mean)\n",
        "X_test_mean_sc = sc.transform(X_test_mean)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_classifier = LogisticRegression(random_state = 51, penalty = 'none',max_iter=100)\n",
        "lr_classifier.fit(X_train_mean, y_train_mean)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
            "563        20.92         25.09  ...          0.2929                  0.09873\n",
            "564        21.56         22.39  ...          0.2060                  0.07115\n",
            "565        20.13         28.25  ...          0.2572                  0.06637\n",
            "566        16.60         28.08  ...          0.2218                  0.07820\n",
            "567        20.60         29.33  ...          0.4087                  0.12400\n",
            "568         7.76         24.54  ...          0.2871                  0.07039\n",
            "\n",
            "[6 rows x 30 columns]\n",
            "564    0.0\n",
            "565    0.0\n",
            "566    0.0\n",
            "567    0.0\n",
            "568    1.0\n",
            "Name: target, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='none',\n",
              "                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QFYl-A8lPO0",
        "outputId": "c6cf0e44-92ec-44af-9ebb-7f8e173e9b0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_lr_mean = lr_classifier.predict(X_test_mean)\n",
        "print(\"Accuracy by logistic regression for all 30 parameters : \",accuracy_score(y_test_mean, y_pred_lr_mean))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy by logistic regression for all 30 parameters :  0.9649122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg964PzamVXW"
      },
      "source": [
        "##getting accuracy of 96% with logistic regression with mean data only(10 attributes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7JXSoA7mIeE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}